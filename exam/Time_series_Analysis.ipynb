{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpmjKK8srQ0H"
      },
      "source": [
        "Elementary Time Series Models\n",
        "ðŸ”· Objective:\n",
        "Apply and visualize elementary time series forecasting models on a sample dataset (AirPassengers or synthetic sales data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYGlrn5qrFl6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Sample monthly sales data (you can replace with your own time series)\n",
        "data = {\n",
        "    'Month': pd.date_range(start='2022-01-01', periods=24, freq='M'),\n",
        "    'Sales': [200, 220, 230, 250, 270, 300, 310, 320, 340, 360, 370, 390,\n",
        "              400, 420, 440, 460, 480, 500, 520, 540, 560, 580, 600, 620]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "df.set_index('Month', inplace=True)\n",
        "\n",
        "# Plot original series\n",
        "df['Sales'].plot(title='Original Sales Time Series', marker='o')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# ---------- Naive Forecast ----------\n",
        "naive_forecast = df['Sales'].shift(1)\n",
        "\n",
        "# ---------- Moving Average ----------\n",
        "window = 3\n",
        "moving_avg_forecast = df['Sales'].rolling(window=window).mean()\n",
        "\n",
        "# ---------- Simple Exponential Smoothing ----------\n",
        "model_ses = SimpleExpSmoothing(df['Sales']).fit(smoothing_level=0.2, optimized=False)\n",
        "ses_forecast = model_ses.fittedvalues\n",
        "\n",
        "# Plot all models\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df['Sales'], label='Original')\n",
        "plt.plot(naive_forecast, label='Naive Forecast', linestyle='--')\n",
        "plt.plot(moving_avg_forecast, label=f'Moving Avg ({window})', linestyle='-.')\n",
        "plt.plot(ses_forecast, label='Simple Exp Smoothing', linestyle=':')\n",
        "plt.title('Elementary Time Series Models')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# ---------- Evaluation (last 10 points) ----------\n",
        "actual = df['Sales'][-10:]\n",
        "naive_pred = naive_forecast[-10:]\n",
        "ses_pred = ses_forecast[-10:]\n",
        "ma_pred = moving_avg_forecast[-10:]\n",
        "\n",
        "print(\"Mean Squared Error:\")\n",
        "print(\"Naive:\", mean_squared_error(actual[1:], naive_pred[1:]))\n",
        "print(\"Moving Average:\", mean_squared_error(actual[2:], ma_pred[2:]))\n",
        "print(\"Simple Exponential Smoothing:\", mean_squared_error(actual, ses_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyyamTT_rpgR"
      },
      "source": [
        "Program: Time Series Decomposition\n",
        "ðŸ”· Objective:\n",
        "Decompose a time series dataset into trend, seasonal and residual components using additive or multiplicative models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTLqwPX3r7_t"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "# Sample time series data (monthly)\n",
        "data = {\n",
        "    'Month': pd.date_range(start='2020-01-01', periods=24, freq='M'),\n",
        "    'Sales': [250, 270, 300, 310, 330, 360, 400, 420, 410, 390, 380, 370,\n",
        "              260, 280, 320, 340, 350, 370, 410, 430, 420, 400, 390, 380]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.set_index('Month', inplace=True)\n",
        "\n",
        "# Decompose the time series\n",
        "result = seasonal_decompose(df['Sales'], model='additive', period=12)\n",
        "\n",
        "# Plot the components\n",
        "result.plot()\n",
        "plt.suptitle(\"Time Series Decomposition\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Optional: Print components\n",
        "print(\"Trend:\\n\", result.trend.dropna().head())\n",
        "print(\"\\nSeasonal:\\n\", result.seasonal.head(12))  # one season\n",
        "print(\"\\nResidual:\\n\", result.resid.dropna().head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE-_vCPqsHl5"
      },
      "source": [
        "Elementary model evaluation techniques for the given data after fitting the models. â€“ BIAS, MAD, MAPE, MSE.Below is a Python program to perform elementary model evaluation techniques for time series forecasting, including:\n",
        "\n",
        "BIAS (Forecast Bias)\n",
        "\n",
        "MAD (Mean Absolute Deviation)\n",
        "\n",
        "MAPE (Mean Absolute Percentage Error)\n",
        "\n",
        "MSE (Mean Squared Error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUDbYefasR2X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulated time series data (actual vs forecasted)\n",
        "actual = np.array([120, 130, 125, 145, 150, 165, 160, 170, 180, 175])\n",
        "forecast = np.array([118, 132, 128, 140, 148, 160, 158, 172, 178, 174])\n",
        "\n",
        "# Convert to DataFrame for ease\n",
        "df = pd.DataFrame({'Actual': actual, 'Forecast': forecast})\n",
        "\n",
        "# Compute Errors\n",
        "df['Error'] = df['Actual'] - df['Forecast']\n",
        "df['Abs_Error'] = df['Error'].abs()\n",
        "df['Squared_Error'] = df['Error'] ** 2\n",
        "df['APE'] = (df['Abs_Error'] / df['Actual']) * 100\n",
        "\n",
        "# Evaluation Metrics\n",
        "bias = df['Error'].mean()\n",
        "mad = df['Abs_Error'].mean()\n",
        "mse = df['Squared_Error'].mean()\n",
        "mape = df['APE'].mean()\n",
        "\n",
        "# Output\n",
        "print(\"BIAS (Forecast Bias):\", round(bias, 2))\n",
        "print(\"MAD (Mean Absolute Deviation):\", round(mad, 2))\n",
        "print(\"MSE (Mean Squared Error):\", round(mse, 2))\n",
        "print(\"MAPE (Mean Absolute Percentage Error):\", round(mape, 2), \"%\")\n",
        "\n",
        "# Optional: Plot actual vs forecast\n",
        "plt.plot(df['Actual'], label='Actual', marker='o')\n",
        "plt.plot(df['Forecast'], label='Forecast', marker='x')\n",
        "plt.title(\"Actual vs Forecast\")\n",
        "plt.xlabel(\"Time Index\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bkxLSjQs5ec"
      },
      "source": [
        "Python program to check elementary stationarity of a time series using visual inspection and the Augmented Dickey-Fuller (ADF) test, which is a commonly used statistical method in time series analysis\n",
        "\n",
        "Stationarity is vital in time series modeling as many forecasting algorithms assume a stable mean and variance over time. Visual inspection serves as a quick check while the Augmented Dickey-Fuller test provides statistical confirmation. Ensuring stationarity through transformation improves model accuracy and interpretability, particularly in forecasting tasks that rely on ARIMA or similar models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVFSjQD8s7uP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# Generate synthetic time series data (e.g., random walk)\n",
        "np.random.seed(42)\n",
        "n = 200\n",
        "random_walk = np.cumsum(np.random.normal(0, 1, n))\n",
        "\n",
        "# Convert to pandas Series\n",
        "ts = pd.Series(random_walk)\n",
        "\n",
        "# Plot the original time series\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(ts, label='Original Time Series')\n",
        "plt.title('Time Series Plot')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Value')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Perform Augmented Dickey-Fuller test\n",
        "result = adfuller(ts)\n",
        "\n",
        "# Display results\n",
        "print('ADF Statistic:', result[0])\n",
        "print('p-value:', result[1])\n",
        "print('Critical Values:')\n",
        "for key, value in result[4].items():\n",
        "    print(f'   {key}: {value}')\n",
        "\n",
        "# Check stationarity\n",
        "if result[1] < 0.05:\n",
        "    print(\"\\nConclusion: The time series is stationary (reject null hypothesis).\")\n",
        "else:\n",
        "    print(\"\\nConclusion: The time series is non-stationary (fail to reject null hypothesis).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iTeyZcetImO"
      },
      "source": [
        "Python program that applies the Augmented Dickey-Fuller (ADF) test to check stationarity of a time series dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wYjuiVHtKj0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# Create sample non-stationary time series (random walk)\n",
        "np.random.seed(42)\n",
        "n = 100\n",
        "steps = np.random.normal(loc=0, scale=1, size=n)\n",
        "data = np.cumsum(steps)  # Random walk = non-stationary\n",
        "time_series = pd.Series(data)\n",
        "\n",
        "# Plot the time series\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(time_series)\n",
        "plt.title(\"Generated Random Walk (Non-Stationary Series)\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Apply Augmented Dickey-Fuller Test\n",
        "result = adfuller(time_series)\n",
        "\n",
        "# Display the results\n",
        "print(\"ADF Statistic:\", result[0])\n",
        "print(\"p-value:\", result[1])\n",
        "print(\"Critical Values:\")\n",
        "for key, value in result[4].items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "# Conclusion\n",
        "if result[1] > 0.05:\n",
        "    print(\"Conclusion: The series is likely NON-STATIONARY (p > 0.05)\")\n",
        "else:\n",
        "    print(\"Conclusion: The series is likely STATIONARY (p <= 0.05)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmruYLF_tWqf"
      },
      "source": [
        "Python program to examine the ACF (Autocorrelation Function) and PACF (Partial Autocorrelation Function) for a given time series using statsmodels.\n",
        "\n",
        "**Explanation**\n",
        "ðŸ”¹ What is ACF?\n",
        "The Autocorrelation Function (ACF) measures the correlation between a time series and its past values (lags). It captures direct and indirect dependencies.\n",
        "\n",
        "ðŸ”¹ What is PACF?\n",
        "The Partial Autocorrelation Function (PACF) shows the direct correlation between the series and its lags, after removing the effect of intermediate lags.\n",
        "\n",
        "ðŸ”¹ AR Process and Interpretation:\n",
        "ACF of an AR(p) process decays gradually.\n",
        "\n",
        "PACF cuts off after lag p (e.g., AR(2) has PACF spikes at lag 1 and 2, then drops).\n",
        "\n",
        "ðŸ“Š Use Cases\n",
        "Use Case\tDescription\n",
        "ARIMA Modeling\tACF and PACF are essential for selecting the order (p, d, q) in ARIMA.\n",
        "Seasonal Analysis\tHelps identify repeated patterns or seasonality in data.\n",
        "Forecast Diagnostics\tACF of residuals used to check model fit and independence.\n",
        "Signal Processing\tUnderstand temporal relationships in engineering signals.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfoYb5FVtaNE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "# Sample synthetic time series data (or load your own)\n",
        "np.random.seed(42)\n",
        "n = 100\n",
        "time_series = pd.Series(np.random.normal(0, 1, n).cumsum())\n",
        "\n",
        "# Plot the original time series\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(time_series)\n",
        "plt.title(\"Time Series Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot ACF\n",
        "plt.figure(figsize=(10, 4))\n",
        "plot_acf(time_series, lags=20)\n",
        "plt.title(\"Autocorrelation Function (ACF)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot PACF\n",
        "plt.figure(figsize=(10, 4))\n",
        "plot_pacf(time_series, lags=20, method='ywm')\n",
        "plt.title(\"Partial Autocorrelation Function (PACF)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yleF-a5ytftr"
      },
      "source": [
        "Python program to fit a time series model for a given univariate time series dataset using ARIMA, which is a standard technique in time series analysis.\n",
        "\n",
        "Explanation of ARIMA Components:\n",
        "AR (p): Lag of the series itself.\n",
        "\n",
        "I (d): Order of differencing needed to make the series stationary.\n",
        "\n",
        "MA (q): Lag of forecast errors.\n",
        "\n",
        "âœ… Use Cases:\n",
        "Stock price forecasting in finance\n",
        "\n",
        "Sales prediction for retail and e-commerce\n",
        "\n",
        "Temperature forecasting in meteorology\n",
        "\n",
        "Demand forecasting in supply chain management\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnZXw9oNtp35"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from pandas.plotting import autocorrelation_plot\n",
        "\n",
        "# Step 1: Load the univariate time series data\n",
        "# For example purposes, we'll use airline passenger data\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
        "data = pd.read_csv(url, parse_dates=['Month'], index_col='Month')\n",
        "series = data['Passengers']\n",
        "\n",
        "# Step 2: Plot the data\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(series, label=\"Original Series\")\n",
        "plt.title(\"Airline Passenger Time Series\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Passengers\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Step 3: Check for stationarity using Augmented Dickey-Fuller test\n",
        "result = adfuller(series)\n",
        "print('ADF Statistic:', result[0])\n",
        "print('p-value:', result[1])\n",
        "if result[1] <= 0.05:\n",
        "    print(\"The series is stationary\")\n",
        "else:\n",
        "    print(\"The series is not stationary (differencing required)\")\n",
        "\n",
        "# Step 4: Difference the data if needed (here once)\n",
        "diff_series = series.diff().dropna()\n",
        "\n",
        "# Step 5: Fit ARIMA model (p=2, d=1, q=2 as a generic choice; can be tuned)\n",
        "model = ARIMA(series, order=(2, 1, 2))\n",
        "model_fit = model.fit()\n",
        "\n",
        "# Step 6: Summary of model\n",
        "print(model_fit.summary())\n",
        "\n",
        "# Step 7: Forecasting\n",
        "forecast = model_fit.predict(start=len(series), end=len(series)+11, typ='levels')\n",
        "print(\"Forecasted values:\\n\", forecast)\n",
        "\n",
        "# Step 8: Plot forecast\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(series, label=\"Original\")\n",
        "plt.plot(forecast, label=\"Forecast\", linestyle='--')\n",
        "plt.title(\"ARIMA Forecast\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Passengers\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VfgBwrsvUPL"
      },
      "source": [
        "Python program to test the significance of lag coefficients in a time series model (AR model) using the statsmodels library\n",
        "\n",
        "All lag coefficients (L1, L2, L3) have p < 0.05\n",
        "\n",
        "This confirms that they are statistically significant\n",
        "\n",
        "The model effectively captures the autoregressive process\n",
        "\n",
        "ðŸ›  Use Cases:\n",
        "Financial Modeling â€“ Stock return prediction using past values\n",
        "\n",
        "Energy Demand Forecasting â€“ Load forecasting based on previous time steps\n",
        "\n",
        "Sales Forecasting â€“ Using lagged sales data to forecast future values\n",
        "\n",
        "Weather Prediction â€“ Forecasting temperature or rainfall using past data\n",
        "\n",
        "Signal Processing â€“ Modeling autoregressive noise\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFr3DLmdvvji"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load dataset (AirPassengers)\n",
        "from statsmodels.datasets import airpassengers\n",
        "data = airpassengers.load_pandas().data\n",
        "data['Month'] = pd.to_datetime(data['month'])\n",
        "data.set_index('Month', inplace=True)\n",
        "ts = data['AirPassengers']\n",
        "\n",
        "# Plot the time series\n",
        "ts.plot(title=\"Monthly Air Passengers\")\n",
        "plt.ylabel(\"Passengers\")\n",
        "plt.show()\n",
        "\n",
        "# Fit AR model with selected lags\n",
        "max_lag = 12\n",
        "model = AutoReg(ts, lags=max_lag, old_names=False)\n",
        "result = model.fit()\n",
        "\n",
        "# Summary of model coefficients\n",
        "print(result.summary())\n",
        "\n",
        "# Extract p-values of coefficients\n",
        "print(\"\\nLag Coefficient Significance:\")\n",
        "for lag, pval in zip(result.params.index, result.pvalues):\n",
        "    significance = \"Significant\" if pval < 0.05 else \"Not Significant\"\n",
        "    print(f\"{lag}: p-value = {pval:.4f} â†’ {significance}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Mq0eLxHwJyH"
      },
      "source": [
        "Python program that demonstrates how to apply ARIMA/ARMA model for time series forecasting, including model fitting, evaluation, and visualization using a real-world dataset.\n",
        "\n",
        "Use Cases of ARIMA/ARMA in Real World\n",
        "Stock Price Prediction\n",
        "Forecasting stock closing prices to support investment strategies.\n",
        "\n",
        "Energy Consumption Forecasting\n",
        "Predicting power usage in smart grid systems or buildings.\n",
        "\n",
        "Weather Prediction\n",
        "Estimating future temperature or rainfall based on historical data.\n",
        "\n",
        "Retail Sales Forecasting\n",
        "Helping businesses manage inventory by forecasting future sales.\n",
        "\n",
        "Economic Indicators\n",
        "Forecasting GDP, inflation, or unemployment trends for policy decisions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va2bfjADyXTJ",
        "outputId": "d4f47865-7535-4868-d72d-2e02d8b45c6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.5)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.65)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.16.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.8)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.14.1)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (2025.7.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas matplotlib statsmodels yfinance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQOlQqSwwL_y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load dataset\n",
        "# Using AirPassengers dataset (Monthly Airline Passengers from 1949 to 1960)\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\"\n",
        "data = pd.read_csv(url, parse_dates=['Month'], index_col='Month')\n",
        "\n",
        "# Plot raw data\n",
        "data.plot(title='Monthly Airline Passengers', figsize=(10, 4))\n",
        "plt.ylabel('Passengers')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Train-test split\n",
        "train = data[:'1958']\n",
        "test = data['1959':]\n",
        "\n",
        "# Fit ARIMA model: order=(p,d,q)\n",
        "# After analysis, order (2,1,2) is used\n",
        "model = ARIMA(train, order=(2, 1, 2))\n",
        "model_fit = model.fit()\n",
        "\n",
        "# Summary of the model\n",
        "print(model_fit.summary())\n",
        "\n",
        "# Forecast on test data\n",
        "forecast = model_fit.forecast(steps=len(test))\n",
        "test['Forecast'] = forecast.values\n",
        "\n",
        "# Plot actual vs predicted\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train.index, train.values, label='Train')\n",
        "plt.plot(test.index, test['Passengers'], label='Actual')\n",
        "plt.plot(test.index, test['Forecast'], label='Forecast')\n",
        "plt.legend()\n",
        "plt.title(\"ARIMA Forecast vs Actual\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Evaluation metrics\n",
        "mse = mean_squared_error(test['Passengers'], test['Forecast'])\n",
        "mae = mean_absolute_error(test['Passengers'], test['Forecast'])\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Model Evaluation Metrics:\")\n",
        "print(\"Mean Absolute Error (MAE):\", round(mae, 2))\n",
        "print(\"Mean Squared Error (MSE):\", round(mse, 2))\n",
        "print(\"Root Mean Squared Error (RMSE):\", round(rmse, 2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38p1PpsdwiGR"
      },
      "source": [
        "Python program to examine the feasibility and implementation of the VAR (Vector Autoregression) model in time series analysis using multivariate time series data\n",
        "\n",
        "**Explanation**\n",
        "Two artificial time series are created: GDP Growth and Inflation.\n",
        "\n",
        "The Augmented Dickey-Fuller (ADF) test checks for stationarity.\n",
        "\n",
        "If not stationary, the series are differenced.\n",
        "\n",
        "The VAR model is fitted using the optimal lag determined by information criteria.\n",
        "\n",
        "Forecasting is done for the next 5 time points, and results are plotted.\n",
        "\n",
        "ðŸ“Œ **Use Cases of VAR Model**\n",
        "Macroeconomic Forecasting: Forecast GDP, inflation, and interest rates jointly.\n",
        "\n",
        "Policy Impact Analysis: Evaluate the influence of monetary policy on different economic indicators.\n",
        "\n",
        "Energy Market Analysis: Examine interactions between oil prices, gas demand, and stock indices.\n",
        "\n",
        "Finance: Capture interdependence among stock returns, volatility, and exchange rates.\n",
        "\n",
        "Marketing Analytics: Explore mutual effects of product pricing and sales across categories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFzUiql9x6ex"
      },
      "outputs": [],
      "source": [
        "%pip install statsmodels pandas matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWKtsK-owk15"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.api import VAR\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tools.eval_measures import rmse\n",
        "\n",
        "# Load dataset (using macroeconomic indicators dataset)\n",
        "from statsmodels.datasets import macrodata\n",
        "data = macrodata.load_pandas().data\n",
        "\n",
        "# Convert date range to datetime format\n",
        "index = pd.date_range(start='1959-01-01', periods=len(data), freq='Q')\n",
        "df = pd.DataFrame(data, columns=['realgdp', 'realcons', 'realinv'], index=index)\n",
        "\n",
        "# Plot raw data\n",
        "df.plot(title='Macroeconomic Time Series')\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Stationarity check using Augmented Dickey-Fuller Test\n",
        "def adf_test(series):\n",
        "    result = adfuller(series)\n",
        "    print(f\"ADF Statistic for {series.name}: {result[0]}\")\n",
        "    print(f\"p-value: {result[1]}\")\n",
        "    return result[1] > 0.05  # True if non-stationary\n",
        "\n",
        "non_stationary = [col for col in df.columns if adf_test(df[col])]\n",
        "\n",
        "# Differencing to achieve stationarity\n",
        "df_diff = df.diff().dropna()\n",
        "\n",
        "# Confirm stationarity\n",
        "print(\"\\nAfter differencing:\")\n",
        "for col in df_diff.columns:\n",
        "    adf_test(df_diff[col])\n",
        "\n",
        "# Splitting into train and test sets\n",
        "n_obs = 10\n",
        "train, test = df_diff[:-n_obs], df_diff[-n_obs:]\n",
        "\n",
        "# Fit VAR model\n",
        "model = VAR(train)\n",
        "lag_order = model.select_order(maxlags=15)\n",
        "print(\"\\nSelected Lags by AIC:\", lag_order.aic)\n",
        "\n",
        "model_fitted = model.fit(lag_order.aic)\n",
        "\n",
        "# Summary\n",
        "print(model_fitted.summary())\n",
        "\n",
        "# Forecast\n",
        "forecast_input = train.values[-model_fitted.k_ar:]\n",
        "forecast = model_fitted.forecast(y=forecast_input, steps=n_obs)\n",
        "\n",
        "# Convert forecast to DataFrame\n",
        "forecast_df = pd.DataFrame(forecast, index=test.index, columns=test.columns)\n",
        "\n",
        "# Plot forecasts vs actual\n",
        "for col in df.columns:\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(df_diff[col][-n_obs:], label='Actual')\n",
        "    plt.plot(forecast_df[col], label='Forecast', linestyle='--')\n",
        "    plt.title(f\"{col} Forecast vs Actual\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Calculate RMSE\n",
        "for col in df.columns:\n",
        "    error = rmse(test[col], forecast_df[col])\n",
        "    print(f\"RMSE for {col}: {error:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72cgI-ndxSU9"
      },
      "source": [
        "Python program that applies the ARCH (Autoregressive Conditional Heteroskedasticity) model in time series analysis using the arch package.\n",
        "**Explanation**:\n",
        "A synthetic return series is simulated with ARCH effects.\n",
        "\n",
        "arch_model(..., vol='ARCH', p=1) fits an ARCH(1) model.\n",
        "\n",
        "The model estimates time-varying volatility.\n",
        "\n",
        "The summary shows key metrics like AIC, BIC, and estimated coefficients.\n",
        "\n",
        "A plot displays the conditional volatility, which changes over time.\n",
        "\n",
        "**ðŸ“Š Use Cases:**\n",
        "Financial return modeling\n",
        "\n",
        "Risk estimation (e.g., Value at Risk)\n",
        "\n",
        "Detecting volatility clustering in assets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOQdky22xj6q"
      },
      "outputs": [],
      "source": [
        "%pip install arch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3u80tjnTxl33"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from arch import arch_model\n",
        "\n",
        "# Simulate time series data (daily returns)\n",
        "np.random.seed(42)\n",
        "n = 1000\n",
        "eps = np.random.normal(0, 1, n)\n",
        "alpha = 0.1\n",
        "returns = []\n",
        "for i in range(n):\n",
        "    if i == 0:\n",
        "        returns.append(eps[i])\n",
        "    else:\n",
        "        var = alpha * returns[i-1]**2\n",
        "        returns.append(np.random.normal(0, np.sqrt(var + 1e-4)))\n",
        "\n",
        "returns = pd.Series(returns)\n",
        "\n",
        "# Plot the returns\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(returns)\n",
        "plt.title('Simulated Financial Returns')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Return')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Fit ARCH(1) model\n",
        "model = arch_model(returns, vol='ARCH', p=1)\n",
        "results = model.fit(disp='off')\n",
        "\n",
        "# Print model summary\n",
        "print(results.summary())\n",
        "\n",
        "# Plot conditional volatility\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(results.conditional_volatility)\n",
        "plt.title('Estimated Conditional Volatility (ARCH Model)')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Volatility')\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
